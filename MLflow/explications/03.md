# 0 - Ajouts par rapport au script précédent 💀🚨

Dans cette version, **nous avons ajouté une nouvelle fonctionnalité pour configurer et vérifier l’URI de suivi de MLflow** afin de faciliter la connexion avec un serveur de suivi externe. Les ajouts sont les suivants :

💀🚨 **Configuration de l’URI de suivi** avec `mlflow.set_tracking_uri()` pour spécifier un emplacement centralisé pour enregistrer les expériences, par exemple un serveur distant ou un emplacement spécifique.

💀🚨 **Affichage de l’URI de suivi** avec `mlflow.get_tracking_uri()` pour confirmer que MLflow est bien configuré pour enregistrer les expériences dans l’emplacement souhaité.

Ces ajouts permettent de rediriger le suivi des expériences vers un serveur MLflow, utile dans des environnements collaboratifs ou pour centraliser les expériences.

---

# 1 - Script 🎛️

Ce script Python utilise le modèle ElasticNet pour prédire la qualité du vin et intègre la configuration de l’URI de suivi pour centraliser le suivi des expériences MLflow.

```python
# Importation des bibliothèques nécessaires
import warnings  # ⚠️ Pour gérer les avertissements dans le programme
import argparse  # 📝 Pour gérer les arguments de la ligne de commande
import logging  # 🛠️ Pour gérer les messages de journalisation
import pandas as pd  # 🧮 Pour manipuler les données sous forme de DataFrame
import numpy as np  # 🔢 Pour les calculs numériques, notamment les matrices
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # 📊 Pour les métriques d'évaluation
from sklearn.model_selection import train_test_split  # 📚 Pour diviser les données en ensembles d'entraînement et de test
from sklearn.linear_model import ElasticNet  # 📈 Pour utiliser le modèle de régression ElasticNet
import mlflow  # 💀🚨 Pour configurer et gérer le suivi des expériences

# Configuration de la journalisation pour ignorer les messages de niveau inférieur à "WARNING"
logging.basicConfig(level=logging.WARN)
logger = logging.getLogger(__name__)

# Initialisation d'un analyseur d'arguments pour la ligne de commande
parser = argparse.ArgumentParser()
parser.add_argument("--alpha", type=float, required=False, default=0.5)  # ⚙️ Argument "alpha" pour ElasticNet, par défaut 0.5
parser.add_argument("--l1_ratio", type=float, required=False, default=0.5)  # ⚙️ Argument "l1_ratio" pour ElasticNet, par défaut 0.5
args = parser.parse_args()  # 🛠️ Analyse des arguments fournis

# Fonction pour évaluer les performances du modèle avec plusieurs métriques
def eval_metrics(actual, pred):
    rmse = np.sqrt(mean_squared_error(actual, pred))  # 🧮 Calcul de l'erreur quadratique moyenne (RMSE)
    mae = mean_absolute_error(actual, pred)  # 🧮 Calcul de l'erreur absolue moyenne (MAE)
    r2 = r2_score(actual, pred)  # 📊 Calcul du score R², qui mesure la précision du modèle
    return rmse, mae, r2  # ➡️ Retourne les trois métriques

# Code principal du programme
if __name__ == "__main__":
    warnings.filterwarnings("ignore")  # ⚠️ Ignore les avertissements
    np.random.seed(40)  # 🎲 Fixe la graine aléatoire pour des résultats reproductibles

    # Lecture des données depuis le fichier CSV "red-wine-quality.csv" (local)
    data = pd.read_csv("red-wine-quality.csv")
    data.to_csv("data/red-wine-quality.csv", index=False)  # 💾 Enregistrement des données dans un nouveau fichier

    # Division des données en ensembles d'entraînement et de test (75% - 25%)
    train, test = train_test_split(data)

    # Définition des variables de prédiction et de la cible "quality"
    train_x = train.drop(["quality"], axis=1)  # Données d'entraînement sans la colonne "quality"
    test_x = test.drop(["quality"], axis=1)  # Données de test sans la colonne "quality"
    train_y = train[["quality"]]  # Valeurs de "quality" pour l'entraînement
    test_y = test[["quality"]]  # Valeurs de "quality" pour le test

    # Récupération des valeurs des arguments alpha et l1_ratio
    alpha = args.alpha
    l1_ratio = args.l1_ratio

    # 💀🚨 Configuration de l'URI de suivi MLflow
    mlflow.set_tracking_uri(uri="")  # ➡️ Indiquer l’URL du serveur de suivi MLflow

    # 💀🚨 Affichage de l'URI de suivi pour confirmation
    print("The set tracking URI is ", mlflow.get_tracking_uri())

    # Initialisation et entraînement du modèle ElasticNet
    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
    lr.fit(train_x, train_y)

    # Prédiction des qualités pour les données de test
    predicted_qualities = lr.predict(test_x)

    # Évaluation des performances du modèle avec les métriques
    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)

    # Affichage des résultats
    print("ElasticNet model (alpha={:f}, l1_ratio={:f}):".format(alpha, l1_ratio))
    print("  RMSE: %s" % rmse)
    print("  MAE: %s" % mae)
    print("  R2: %s" % r2)
```

---

# 2 - Exécution 🏃‍♂️

Pour exécuter ce script avec MLflow et la configuration de l’URI de suivi, nous utilisons le script `setup_mlflow_and_run.sh` pour lancer le serveur MLflow en arrière-plan et exécuter le script Python.

### Script Complet `setup_mlflow_and_run.sh`

```bash
#!/bin/bash

# 🌐 Mettre à jour le système
sudo apt update && sudo apt upgrade -y

# 🐍 Installer Python et pip
sudo apt install python3 python3-pip -y

# ⚙️ Créer et activer un environnement virtuel pour MLflow
python3 -m venv mlflow-env
source mlflow-env/bin/activate

# 📦 Installer MLflow, scikit-learn et pandas pour la modélisation
pip install mlflow scikit-learn pandas numpy

# 📂 Créer les répertoires pour MLflow
mkdir -p ~/mlflow-experiments/database

# 🚀 Démarrer le serveur MLflow en arrière-plan
mlflow server --backend-store-uri sqlite:///~/mlflow-experiments/database/mlflow.db --default-artifact-root file:~/mlflow-experiments/mlruns --host 0.0.0.0 --port 5000 &

# ⏳ Attendre quelques secondes pour s'assurer que le serveur MLflow est lancé
sleep 5

# ▶️ Exécuter le script Python avec les configurations alpha et l1_ratio
python3 votre_script.py --alpha 0.5 --l1_ratio 0.5
```

### Exécution du Script Complet

1. **Enregistrer le script** : Sauvegardez le script ci-dessus sous le nom `setup_mlflow_and_run.sh`.
2. **Rendre le script exécutable** :
   ```bash
   chmod +x setup_mlflow_and_run.sh
   ```
3. **Lancer le script** :
   ```bash
   ./setup_mlflow_and_run.sh
   ```

Ce script :
- 🖥️ Met à jour le système et installe les dépendances.
- 🚀 Lance le serveur MLflow en arrière-plan.
- ⏳ Attend quelques secondes pour garantir que le serveur est lancé.
- 🏃 Exécute le script Python de modélisation avec les paramètres `alpha` et `l1_ratio`.

### Accéder à l'interface MLflow 🌐

Après l'exécution, vous pouvez accéder à l'interface MLflow en ouvrant l’adresse suivante dans votre navigateur :
```
http://<IP-de-votre-VM>:5000
```

Assurez-vous de remplacer `<IP-de-votre-VM>` par l’adresse IP de votre VM.

---

# 3 - Annexe des Explications 📖

### 1. Ajouts par rapport au script précédent 💀🚨

Dans ce script, **nous avons ajouté la configuration de l’URI de suivi** de MLflow pour indiquer où enregistrer les expériences. Cela permet de spécifier un serveur centralisé pour enregistrer toutes les expériences.

### 2. Mise à Jour du Système et Installation des Dépendances

Cette étape assure que votre VM dispose des dernières mises à jour de sécurité et de fonctionnalités pour éviter les erreurs futures.

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install python3 python3-pip -y
```

### 3. Création d’un Environnement Virtuel

L’environnement virtuel `mlflow-env` isole les dépendances de MLflow et du script Python du reste du système, pour un environnement reproductible et stable.

```bash
python3 -m venv mlflow-env
source mlflow-env/bin/activate
``

`

### 4. Installation des Bibliothèques Python

Ici, nous installons MLflow pour le suivi des expériences, scikit-learn et pandas pour les manipulations et calculs sur les données, et numpy pour les opérations numériques.

```bash
pip install mlflow scikit-learn pandas numpy
```

### 5. Configuration des Répertoires MLflow

Ces répertoires stockent les métadonnées et les artefacts générés par MLflow.

```bash
mkdir -p ~/mlflow-experiments/database
```

- **`~/mlflow-experiments/database`** : Base de données SQLite pour stocker les informations des expériences.
- **`~/mlflow-experiments/mlruns`** : Dossier local pour les artefacts (modèles, métriques, etc.).

### 6. Démarrage du Serveur MLflow en Arrière-Plan

Cette commande démarre le serveur MLflow en arrière-plan pour enregistrer les expériences. Assurez-vous que l’adresse IP `0.0.0.0` et le port `5000` sont disponibles pour accéder au serveur depuis d’autres machines.

```bash
mlflow server --backend-store-uri sqlite:///~/mlflow-experiments/database/mlflow.db --default-artifact-root file:~/mlflow-experiments/mlruns --host 0.0.0.0 --port 5000 &
```

### 7. Pause pour le Démarrage du Serveur

Cette pause (`sleep 5`) garantit que le serveur MLflow est opérationnel avant l’exécution du script Python.

```bash
sleep 5
```

### 8. Exécution du Script Python avec ElasticNet

Le script Python est lancé avec les paramètres `alpha` et `l1_ratio`, permettant une personnalisation rapide du modèle ElasticNet.

```bash
python3 votre_script.py --alpha 0.5 --l1_ratio 0.5
```

Avec ce tutoriel, vous pouvez maintenant installer, configurer et exécuter MLflow pour gérer vos expériences de machine learning !
