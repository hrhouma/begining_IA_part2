

# 0 - Ajouts par rapport au script précédent 💀🚨

Dans cette version, **nous avons ajouté plusieurs fonctionnalités avancées** pour mieux organiser et documenter les expériences dans MLflow, notamment la gestion des artefacts et l'ajout de métadonnées aux expériences. Les ajouts incluent :

💀🚨 **Création d’une expérience avec artefacts** : La fonction `mlflow.create_experiment()` permet de créer une nouvelle expérience avec un emplacement d'artefacts personnalisé. Cela facilite l’organisation des résultats.

💀🚨 **Ajout de tags aux expériences** : En ajoutant des tags dans `mlflow.create_experiment()`, on peut associer des métadonnées (comme version et priorité) pour suivre les priorités et versions des expériences.

💀🚨 **Utilisation de `Path` pour l'emplacement des artefacts** : L’emplacement des artefacts est défini en utilisant `Path.cwd().joinpath("myartifacts").as_uri()`, ce qui garantit un chemin d’accès dynamique et adaptable.

💀🚨 **Affichage des informations détaillées de l’expérience** : Le script affiche des informations comme le nom de l'expérience, les tags, et le chemin des artefacts pour permettre un meilleur suivi.

Ces ajouts permettent une gestion plus fine des expériences et offrent des possibilités d’organisation et de priorisation des travaux dans MLflow.

---

# 1 - Script 🎛️

Ce script Python utilise le modèle ElasticNet pour prédire la qualité du vin et crée une nouvelle expérience avec des artefacts et des métadonnées dans MLflow.

```python
# Importation des bibliothèques nécessaires
import warnings  # ⚠️ Pour gérer les avertissements dans le programme
import argparse  # 📝 Pour gérer les arguments de la ligne de commande
import logging  # 🛠️ Pour gérer les messages de journalisation
import pandas as pd  # 🧮 Pour manipuler les données sous forme de DataFrame
import numpy as np  # 🔢 Pour les calculs numériques, notamment les matrices
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # 📊 Pour les métriques d'évaluation
from sklearn.model_selection import train_test_split  # 📚 Pour diviser les données en ensembles d'entraînement et de test
from sklearn.linear_model import ElasticNet  # 📈 Pour utiliser le modèle de régression ElasticNet
import mlflow  # 💀🚨 Pour configurer et gérer le suivi des expériences
import mlflow.sklearn  # 💀🚨 Pour enregistrer des modèles scikit-learn dans MLflow
from pathlib import Path  # 💀🚨 Pour gérer les chemins d'accès des artefacts

# Configuration de la journalisation pour ignorer les messages de niveau inférieur à "WARNING"
logging.basicConfig(level=logging.WARN)
logger = logging.getLogger(__name__)

# Initialisation d'un analyseur d'arguments pour la ligne de commande
parser = argparse.ArgumentParser()
parser.add_argument("--alpha", type=float, required=False, default=0.7)  # ⚙️ Argument "alpha" pour ElasticNet, par défaut 0.7
parser.add_argument("--l1_ratio", type=float, required=False, default=0.7)  # ⚙️ Argument "l1_ratio" pour ElasticNet, par défaut 0.7
args = parser.parse_args()  # 🛠️ Analyse des arguments fournis

# Fonction pour évaluer les performances du modèle avec plusieurs métriques
def eval_metrics(actual, pred):
    rmse = np.sqrt(mean_squared_error(actual, pred))  # 🧮 Calcul de l'erreur quadratique moyenne (RMSE)
    mae = mean_absolute_error(actual, pred)  # 🧮 Calcul de l'erreur absolue moyenne (MAE)
    r2 = r2_score(actual, pred)  # 📊 Calcul du score R², qui mesure la précision du modèle
    return rmse, mae, r2  # ➡️ Retourne les trois métriques

# Code principal du programme
if __name__ == "__main__":
    warnings.filterwarnings("ignore")  # ⚠️ Ignore les avertissements
    np.random.seed(40)  # 🎲 Fixe la graine aléatoire pour des résultats reproductibles

    # Lecture des données depuis le fichier CSV "red-wine-quality.csv" (local)
    data = pd.read_csv("red-wine-quality.csv")

    # Division des données en ensembles d'entraînement et de test (75% - 25%)
    train, test = train_test_split(data)

    # Définition des variables de prédiction et de la cible "quality"
    train_x = train.drop(["quality"], axis=1)  # Données d'entraînement sans la colonne "quality"
    test_x = test.drop(["quality"], axis=1)  # Données de test sans la colonne "quality"
    train_y = train[["quality"]]  # Valeurs de "quality" pour l'entraînement
    test_y = test[["quality"]]  # Valeurs de "quality" pour le test

    # Récupération des valeurs des arguments alpha et l1_ratio
    alpha = args.alpha
    l1_ratio = args.l1_ratio

    # 💀🚨 Configuration de l'URI de suivi MLflow
    mlflow.set_tracking_uri(uri="")  # ➡️ Indiquer l’URL du serveur de suivi MLflow

    # 💀🚨 Affichage de l'URI de suivi pour confirmation
    print("The set tracking URI is ", mlflow.get_tracking_uri())

    # 💀🚨 Création d’une expérience avec artefacts et métadonnées
    exp_id = mlflow.create_experiment(
        name="exp_create_exp_artifact",
        tags={"version": "v1", "priority": "p1"},  # Tags pour indiquer la version et la priorité
        artifact_location=Path.cwd().joinpath("myartifacts").as_uri()  # Emplacement des artefacts
    )
    
    # 💀🚨 Récupération et affichage des informations de l'expérience
    get_exp = mlflow.get_experiment(exp_id)
    print("Name: {}".format(get_exp.name))
    print("Experiment_id: {}".format(get_exp.experiment_id))
    print("Artifact Location: {}".format(get_exp.artifact_location))
    print("Tags: {}".format(get_exp.tags))
    print("Lifecycle_stage: {}".format(get_exp.lifecycle_stage))
    print("Creation timestamp: {}".format(get_exp.creation_time))

    # Démarrage de l'exécution dans l'expérience
    with mlflow.start_run(experiment_id=exp_id):
        # Initialisation et entraînement du modèle ElasticNet
        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
        lr.fit(train_x, train_y)

        # Prédiction des qualités pour les données de test
        predicted_qualities = lr.predict(test_x)

        # Évaluation des performances du modèle avec les métriques
        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)

        # Affichage des résultats
        print("ElasticNet model (alpha={:f}, l1_ratio={:f}):".format(alpha, l1_ratio))
        print("  RMSE: %s" % rmse)
        print("  MAE: %s" % mae)
        print("  R2: %s" % r2)

        # Enregistrement des paramètres et métriques dans MLflow
        mlflow.log_param("alpha", alpha)
        mlflow.log_param("l1_ratio", l1_ratio)
        mlflow.log_metric("rmse", rmse)
        mlflow.log_metric("r2", r2)
        mlflow.log_metric("mae", mae)

        # Enregistrement du modèle dans MLflow
        mlflow.sklearn.log_model(lr, "mymodel")
```

---

# 2 - Exécution 🏃‍♂️

Pour exécuter ce script avec MLflow et la gestion des artefacts, nous utilisons le script `setup_mlflow_and_run.sh` pour lancer le serveur MLflow en arrière-plan et exécuter le script Python.

### Script Complet `setup_mlflow_and_run.sh`

```bash
#!/bin/bash

# 🌐 Mettre à jour le système
sudo apt update && sudo apt upgrade -y

# 🐍 Installer Python et pip
sudo apt install python3 python3-pip -y

# ⚙️ Créer et activer un environnement virtuel pour MLflow
python3 -m venv mlflow-env
source mlflow-env/bin/activate

# 📦 Installer MLflow, scikit-learn et pandas pour la modélisation
pip install mlflow scikit-learn pandas numpy

# 📂 Créer les répertoires pour MLflow
mkdir -p ~/mlflow-experiments/database

# 🚀 Démarrer le serveur MLflow en arrière-plan
mlflow server --backend-store-uri sqlite:///~/mlflow-experiments/database/mlflow.db --default-artifact-root file:~/mlflow-experiments/mlruns --host 0.0.0.0 --port 5000 &

# ⏳ Attendre quelques secondes pour s'assurer que le serveur MLflow est lancé
sleep 5

# ▶️ Exécuter le script Python avec les configurations alpha et l1_ratio
python3 votre_script.py --alpha 0.7 --l1_ratio 0.7
```

### Exécution du

 Script Complet

1. **Enregistrer le script** : Sauvegardez le script ci-dessus sous le nom `setup_mlflow_and_run.sh`.
2. **Rendre le script exécutable** :
   ```bash
   chmod +x setup_mlflow_and_run.sh
   ```
3. **Lancer le script** :
   ```bash
   ./setup_mlflow_and_run.sh
   ```

Ce script :
- 🖥️ Met à jour le système et installe les dépendances.
- 🚀 Lance le serveur MLflow en arrière-plan.
- ⏳ Attend quelques secondes pour garantir que le serveur est lancé.
- 🏃 Exécute le script Python de modélisation avec les paramètres `alpha` et `l1_ratio`.

### Accéder à l'interface MLflow 🌐

Après l'exécution, vous pouvez accéder à l'interface MLflow en ouvrant l’adresse suivante dans votre navigateur :
```
http://<IP-de-votre-VM>:5000
```

Assurez-vous de remplacer `<IP-de-votre-VM>` par l’adresse IP de votre VM.

---

# 3 - Annexe des Explications 📖

### 1. Ajouts par rapport au script précédent 💀🚨

Dans ce script, **nous avons ajouté la création d'une nouvelle expérience** avec emplacement d’artefacts et métadonnées pour un suivi complet dans MLflow.

### 2. Création d’un Environnement Virtuel

L’environnement virtuel `mlflow-env` isole les dépendances de MLflow et du script Python du reste du système, pour un environnement reproductible et stable.

```bash
python3 -m venv mlflow-env
source mlflow-env/bin/activate
```

### 3. Configuration des Répertoires MLflow

Ces répertoires stockent les métadonnées et les artefacts générés par MLflow.

```bash
mkdir -p ~/mlflow-experiments/database
```

- **`~/mlflow-experiments/database`** : Base de données SQLite pour stocker les informations des expériences.
- **`~/mlflow-experiments/mlruns`** : Dossier local pour les artefacts (modèles, métriques, etc.).

### 4. Démarrage du Serveur MLflow en Arrière-Plan

Cette commande démarre le serveur MLflow en arrière-plan pour enregistrer les expériences. Assurez-vous que l’adresse IP `0.0.0.0` et le port `5000` sont disponibles pour accéder au serveur depuis d’autres machines.

```bash
mlflow server --backend-store-uri sqlite:///~/mlflow-experiments/database/mlflow.db --default-artifact-root file:~/mlflow-experiments/mlruns --host 0.0.0.0 --port 5000 &
```

Avec ce tutoriel, vous pouvez maintenant installer, configurer et exécuter MLflow pour gérer vos expériences de machine learning !
