

# 0 - Ajouts par rapport au script prÃ©cÃ©dent ğŸ’€ğŸš¨

Dans cette version, **nous avons ajoutÃ© plusieurs fonctionnalitÃ©s avancÃ©es** pour mieux organiser et documenter les expÃ©riences dans MLflow, notamment la gestion des artefacts et l'ajout de mÃ©tadonnÃ©es aux expÃ©riences. Les ajouts incluent :

ğŸ’€ğŸš¨ **CrÃ©ation dâ€™une expÃ©rience avec artefacts** : La fonction `mlflow.create_experiment()` permet de crÃ©er une nouvelle expÃ©rience avec un emplacement d'artefacts personnalisÃ©. Cela facilite lâ€™organisation des rÃ©sultats.

ğŸ’€ğŸš¨ **Ajout de tags aux expÃ©riences** : En ajoutant des tags dans `mlflow.create_experiment()`, on peut associer des mÃ©tadonnÃ©es (comme version et prioritÃ©) pour suivre les prioritÃ©s et versions des expÃ©riences.

ğŸ’€ğŸš¨ **Utilisation de `Path` pour l'emplacement des artefacts** : Lâ€™emplacement des artefacts est dÃ©fini en utilisant `Path.cwd().joinpath("myartifacts").as_uri()`, ce qui garantit un chemin dâ€™accÃ¨s dynamique et adaptable.

ğŸ’€ğŸš¨ **Affichage des informations dÃ©taillÃ©es de lâ€™expÃ©rience** : Le script affiche des informations comme le nom de l'expÃ©rience, les tags, et le chemin des artefacts pour permettre un meilleur suivi.

Ces ajouts permettent une gestion plus fine des expÃ©riences et offrent des possibilitÃ©s dâ€™organisation et de priorisation des travaux dans MLflow.

---

# 1 - Script ğŸ›ï¸

Ce script Python utilise le modÃ¨le ElasticNet pour prÃ©dire la qualitÃ© du vin et crÃ©e une nouvelle expÃ©rience avec des artefacts et des mÃ©tadonnÃ©es dans MLflow.

```python
# Importation des bibliothÃ¨ques nÃ©cessaires
import warnings  # âš ï¸ Pour gÃ©rer les avertissements dans le programme
import argparse  # ğŸ“ Pour gÃ©rer les arguments de la ligne de commande
import logging  # ğŸ› ï¸ Pour gÃ©rer les messages de journalisation
import pandas as pd  # ğŸ§® Pour manipuler les donnÃ©es sous forme de DataFrame
import numpy as np  # ğŸ”¢ Pour les calculs numÃ©riques, notamment les matrices
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # ğŸ“Š Pour les mÃ©triques d'Ã©valuation
from sklearn.model_selection import train_test_split  # ğŸ“š Pour diviser les donnÃ©es en ensembles d'entraÃ®nement et de test
from sklearn.linear_model import ElasticNet  # ğŸ“ˆ Pour utiliser le modÃ¨le de rÃ©gression ElasticNet
import mlflow  # ğŸ’€ğŸš¨ Pour configurer et gÃ©rer le suivi des expÃ©riences
import mlflow.sklearn  # ğŸ’€ğŸš¨ Pour enregistrer des modÃ¨les scikit-learn dans MLflow
from pathlib import Path  # ğŸ’€ğŸš¨ Pour gÃ©rer les chemins d'accÃ¨s des artefacts

# Configuration de la journalisation pour ignorer les messages de niveau infÃ©rieur Ã  "WARNING"
logging.basicConfig(level=logging.WARN)
logger = logging.getLogger(__name__)

# Initialisation d'un analyseur d'arguments pour la ligne de commande
parser = argparse.ArgumentParser()
parser.add_argument("--alpha", type=float, required=False, default=0.7)  # âš™ï¸ Argument "alpha" pour ElasticNet, par dÃ©faut 0.7
parser.add_argument("--l1_ratio", type=float, required=False, default=0.7)  # âš™ï¸ Argument "l1_ratio" pour ElasticNet, par dÃ©faut 0.7
args = parser.parse_args()  # ğŸ› ï¸ Analyse des arguments fournis

# Fonction pour Ã©valuer les performances du modÃ¨le avec plusieurs mÃ©triques
def eval_metrics(actual, pred):
    rmse = np.sqrt(mean_squared_error(actual, pred))  # ğŸ§® Calcul de l'erreur quadratique moyenne (RMSE)
    mae = mean_absolute_error(actual, pred)  # ğŸ§® Calcul de l'erreur absolue moyenne (MAE)
    r2 = r2_score(actual, pred)  # ğŸ“Š Calcul du score RÂ², qui mesure la prÃ©cision du modÃ¨le
    return rmse, mae, r2  # â¡ï¸ Retourne les trois mÃ©triques

# Code principal du programme
if __name__ == "__main__":
    warnings.filterwarnings("ignore")  # âš ï¸ Ignore les avertissements
    np.random.seed(40)  # ğŸ² Fixe la graine alÃ©atoire pour des rÃ©sultats reproductibles

    # Lecture des donnÃ©es depuis le fichier CSV "red-wine-quality.csv" (local)
    data = pd.read_csv("red-wine-quality.csv")

    # Division des donnÃ©es en ensembles d'entraÃ®nement et de test (75% - 25%)
    train, test = train_test_split(data)

    # DÃ©finition des variables de prÃ©diction et de la cible "quality"
    train_x = train.drop(["quality"], axis=1)  # DonnÃ©es d'entraÃ®nement sans la colonne "quality"
    test_x = test.drop(["quality"], axis=1)  # DonnÃ©es de test sans la colonne "quality"
    train_y = train[["quality"]]  # Valeurs de "quality" pour l'entraÃ®nement
    test_y = test[["quality"]]  # Valeurs de "quality" pour le test

    # RÃ©cupÃ©ration des valeurs des arguments alpha et l1_ratio
    alpha = args.alpha
    l1_ratio = args.l1_ratio

    # ğŸ’€ğŸš¨ Configuration de l'URI de suivi MLflow
    mlflow.set_tracking_uri(uri="")  # â¡ï¸ Indiquer lâ€™URL du serveur de suivi MLflow

    # ğŸ’€ğŸš¨ Affichage de l'URI de suivi pour confirmation
    print("The set tracking URI is ", mlflow.get_tracking_uri())

    # ğŸ’€ğŸš¨ CrÃ©ation dâ€™une expÃ©rience avec artefacts et mÃ©tadonnÃ©es
    exp_id = mlflow.create_experiment(
        name="exp_create_exp_artifact",
        tags={"version": "v1", "priority": "p1"},  # Tags pour indiquer la version et la prioritÃ©
        artifact_location=Path.cwd().joinpath("myartifacts").as_uri()  # Emplacement des artefacts
    )
    
    # ğŸ’€ğŸš¨ RÃ©cupÃ©ration et affichage des informations de l'expÃ©rience
    get_exp = mlflow.get_experiment(exp_id)
    print("Name: {}".format(get_exp.name))
    print("Experiment_id: {}".format(get_exp.experiment_id))
    print("Artifact Location: {}".format(get_exp.artifact_location))
    print("Tags: {}".format(get_exp.tags))
    print("Lifecycle_stage: {}".format(get_exp.lifecycle_stage))
    print("Creation timestamp: {}".format(get_exp.creation_time))

    # DÃ©marrage de l'exÃ©cution dans l'expÃ©rience
    with mlflow.start_run(experiment_id=exp_id):
        # Initialisation et entraÃ®nement du modÃ¨le ElasticNet
        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
        lr.fit(train_x, train_y)

        # PrÃ©diction des qualitÃ©s pour les donnÃ©es de test
        predicted_qualities = lr.predict(test_x)

        # Ã‰valuation des performances du modÃ¨le avec les mÃ©triques
        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)

        # Affichage des rÃ©sultats
        print("ElasticNet model (alpha={:f}, l1_ratio={:f}):".format(alpha, l1_ratio))
        print("  RMSE: %s" % rmse)
        print("  MAE: %s" % mae)
        print("  R2: %s" % r2)

        # Enregistrement des paramÃ¨tres et mÃ©triques dans MLflow
        mlflow.log_param("alpha", alpha)
        mlflow.log_param("l1_ratio", l1_ratio)
        mlflow.log_metric("rmse", rmse)
        mlflow.log_metric("r2", r2)
        mlflow.log_metric("mae", mae)

        # Enregistrement du modÃ¨le dans MLflow
        mlflow.sklearn.log_model(lr, "mymodel")
```

---

# 2 - ExÃ©cution ğŸƒâ€â™‚ï¸

Pour exÃ©cuter ce script avec MLflow et la gestion des artefacts, nous utilisons le script `setup_mlflow_and_run.sh` pour lancer le serveur MLflow en arriÃ¨re-plan et exÃ©cuter le script Python.

### Script Complet `setup_mlflow_and_run.sh`

```bash
#!/bin/bash

# ğŸŒ Mettre Ã  jour le systÃ¨me
sudo apt update && sudo apt upgrade -y

# ğŸ Installer Python et pip
sudo apt install python3 python3-pip -y

# âš™ï¸ CrÃ©er et activer un environnement virtuel pour MLflow
python3 -m venv mlflow-env
source mlflow-env/bin/activate

# ğŸ“¦ Installer MLflow, scikit-learn et pandas pour la modÃ©lisation
pip install mlflow scikit-learn pandas numpy

# ğŸ“‚ CrÃ©er les rÃ©pertoires pour MLflow
mkdir -p ~/mlflow-experiments/database

# ğŸš€ DÃ©marrer le serveur MLflow en arriÃ¨re-plan
mlflow server --backend-store-uri sqlite:///~/mlflow-experiments/database/mlflow.db --default-artifact-root file:~/mlflow-experiments/mlruns --host 0.0.0.0 --port 5000 &

# â³ Attendre quelques secondes pour s'assurer que le serveur MLflow est lancÃ©
sleep 5

# â–¶ï¸ ExÃ©cuter le script Python avec les configurations alpha et l1_ratio
python3 votre_script.py --alpha 0.7 --l1_ratio 0.7
```

### ExÃ©cution du

 Script Complet

1. **Enregistrer le script** : Sauvegardez le script ci-dessus sous le nom `setup_mlflow_and_run.sh`.
2. **Rendre le script exÃ©cutable** :
   ```bash
   chmod +x setup_mlflow_and_run.sh
   ```
3. **Lancer le script** :
   ```bash
   ./setup_mlflow_and_run.sh
   ```

Ce script :
- ğŸ–¥ï¸ Met Ã  jour le systÃ¨me et installe les dÃ©pendances.
- ğŸš€ Lance le serveur MLflow en arriÃ¨re-plan.
- â³ Attend quelques secondes pour garantir que le serveur est lancÃ©.
- ğŸƒ ExÃ©cute le script Python de modÃ©lisation avec les paramÃ¨tres `alpha` et `l1_ratio`.

### AccÃ©der Ã  l'interface MLflow ğŸŒ

AprÃ¨s l'exÃ©cution, vous pouvez accÃ©der Ã  l'interface MLflow en ouvrant lâ€™adresse suivante dans votre navigateur :
```
http://<IP-de-votre-VM>:5000
```

Assurez-vous de remplacer `<IP-de-votre-VM>` par lâ€™adresse IP de votre VM.

---

# 3 - Annexe des Explications ğŸ“–

### 1. Ajouts par rapport au script prÃ©cÃ©dent ğŸ’€ğŸš¨

Dans ce script, **nous avons ajoutÃ© la crÃ©ation d'une nouvelle expÃ©rience** avec emplacement dâ€™artefacts et mÃ©tadonnÃ©es pour un suivi complet dans MLflow.

### 2. CrÃ©ation dâ€™un Environnement Virtuel

Lâ€™environnement virtuel `mlflow-env` isole les dÃ©pendances de MLflow et du script Python du reste du systÃ¨me, pour un environnement reproductible et stable.

```bash
python3 -m venv mlflow-env
source mlflow-env/bin/activate
```

### 3. Configuration des RÃ©pertoires MLflow

Ces rÃ©pertoires stockent les mÃ©tadonnÃ©es et les artefacts gÃ©nÃ©rÃ©s par MLflow.

```bash
mkdir -p ~/mlflow-experiments/database
```

- **`~/mlflow-experiments/database`** : Base de donnÃ©es SQLite pour stocker les informations des expÃ©riences.
- **`~/mlflow-experiments/mlruns`** : Dossier local pour les artefacts (modÃ¨les, mÃ©triques, etc.).

### 4. DÃ©marrage du Serveur MLflow en ArriÃ¨re-Plan

Cette commande dÃ©marre le serveur MLflow en arriÃ¨re-plan pour enregistrer les expÃ©riences. Assurez-vous que lâ€™adresse IP `0.0.0.0` et le port `5000` sont disponibles pour accÃ©der au serveur depuis dâ€™autres machines.

```bash
mlflow server --backend-store-uri sqlite:///~/mlflow-experiments/database/mlflow.db --default-artifact-root file:~/mlflow-experiments/mlruns --host 0.0.0.0 --port 5000 &
```

Avec ce tutoriel, vous pouvez maintenant installer, configurer et exÃ©cuter MLflow pour gÃ©rer vos expÃ©riences de machine learning !
