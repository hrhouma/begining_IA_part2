# 0 - Nouveaux ajouts par rapport au script précédent 💀🚨

Dans cette version, nous avons ajouté **de nouvelles fonctionnalités** pour améliorer la gestion et le suivi des exécutions dans MLflow :

💀🚨 **Création et gestion de l’expérience avec `mlflow.set_experiment()`** : La méthode `mlflow.set_experiment()` est utilisée pour définir une nouvelle expérience appelée `"experiment_2"`. Cette expérience est suivie dans MLflow et affiche ses informations de configuration (nom, identifiant, emplacement des artefacts, tags et étapes de cycle de vie).

💀🚨 **Utilisation de `mlflow.start_run()` et `mlflow.end_run()`** : `mlflow.start_run()` démarre une nouvelle exécution sans utiliser `experiment_id` directement. `mlflow.end_run()` termine l’exécution actuelle, facilitant la gestion des exécutions en cours.

💀🚨 **Récupération de l'exécution active avec `mlflow.last_active_run()`** : Cette commande permet d’obtenir l’ID et le nom de l’exécution la plus récente, ce qui est utile pour suivre l'exécution et effectuer un diagnostic rapide.

💀🚨 **Nouveau modèle enregistré avec `mlflow.sklearn.log_model(lr, "my_new_model_1")`** : Nous avons ajouté un nouveau nom `"my_new_model_1"` pour différencier le modèle dans MLflow et améliorer l’organisation des artefacts.

Ces ajouts facilitent le suivi et la gestion des expériences avec des exécutions nommées et identifiables, en apportant plus de flexibilité dans le travail collaboratif et l'organisation des modèles.

---

# 1 - Script 🎛️

Ce script Python utilise le modèle ElasticNet pour prédire la qualité du vin et gère une nouvelle expérience dans MLflow avec des exécutions nommées et des artefacts personnalisés.

```python
# Importation des bibliothèques nécessaires
import warnings  # ⚠️ Pour gérer les avertissements dans le programme
import argparse  # 📝 Pour gérer les arguments de la ligne de commande
import logging  # 🛠️ Pour gérer les messages de journalisation
import pandas as pd  # 🧮 Pour manipuler les données sous forme de DataFrame
import numpy as np  # 🔢 Pour les calculs numériques, notamment les matrices
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # 📊 Pour les métriques d'évaluation
from sklearn.model_selection import train_test_split  # 📚 Pour diviser les données en ensembles d'entraînement et de test
from sklearn.linear_model import ElasticNet  # 📈 Pour utiliser le modèle de régression ElasticNet
import mlflow  # 💀🚨 Pour configurer et gérer le suivi des expériences
import mlflow.sklearn  # 💀🚨 Pour enregistrer des modèles scikit-learn dans MLflow
from pathlib import Path  # 💀🚨 Pour gérer les chemins d'accès des artefacts

# Configuration de la journalisation pour ignorer les messages de niveau inférieur à "WARNING"
logging.basicConfig(level=logging.WARN)
logger = logging.getLogger(__name__)

# Initialisation d'un analyseur d'arguments pour la ligne de commande
parser = argparse.ArgumentParser()
parser.add_argument("--alpha", type=float, required=False, default=0.7)  # ⚙️ Argument "alpha" pour ElasticNet, par défaut 0.7
parser.add_argument("--l1_ratio", type=float, required=False, default=0.7)  # ⚙️ Argument "l1_ratio" pour ElasticNet, par défaut 0.7
args = parser.parse_args()  # 🛠️ Analyse des arguments fournis

# Fonction pour évaluer les performances du modèle avec plusieurs métriques
def eval_metrics(actual, pred):
    rmse = np.sqrt(mean_squared_error(actual, pred))  # 🧮 Calcul de l'erreur quadratique moyenne (RMSE)
    mae = mean_absolute_error(actual, pred)  # 🧮 Calcul de l'erreur absolue moyenne (MAE)
    r2 = r2_score(actual, pred)  # 📊 Calcul du score R², qui mesure la précision du modèle
    return rmse, mae, r2  # ➡️ Retourne les trois métriques

# Code principal du programme
if __name__ == "__main__":
    warnings.filterwarnings("ignore")  # ⚠️ Ignore les avertissements
    np.random.seed(40)  # 🎲 Fixe la graine aléatoire pour des résultats reproductibles

    # Lecture des données depuis le fichier CSV "red-wine-quality.csv" (local)
    data = pd.read_csv("red-wine-quality.csv")

    # Division des données en ensembles d'entraînement et de test (75% - 25%)
    train, test = train_test_split(data)

    # Définition des variables de prédiction et de la cible "quality"
    train_x = train.drop(["quality"], axis=1)  # Données d'entraînement sans la colonne "quality"
    test_x = test.drop(["quality"], axis=1)  # Données de test sans la colonne "quality"
    train_y = train[["quality"]]  # Valeurs de "quality" pour l'entraînement
    test_y = test[["quality"]]  # Valeurs de "quality" pour le test

    # Récupération des valeurs des arguments alpha et l1_ratio
    alpha = args.alpha
    l1_ratio = args.l1_ratio

    # 💀🚨 Configuration de l'URI de suivi MLflow
    mlflow.set_tracking_uri(uri="")  # ➡️ Indiquer l’URL du serveur de suivi MLflow

    # 💀🚨 Affichage de l'URI de suivi pour confirmation
    print("The set tracking URI is ", mlflow.get_tracking_uri())

    # 💀🚨 Définition de l'expérience MLflow
    exp = mlflow.set_experiment(experiment_name="experiment_2")
    print("Name: {}".format(exp.name))
    print("Experiment_id: {}".format(exp.experiment_id))
    print("Artifact Location: {}".format(exp.artifact_location))
    print("Tags: {}".format(exp.tags))
    print("Lifecycle_stage: {}".format(exp.lifecycle_stage))
    print("Creation timestamp: {}".format(exp.creation_time))

    # 💀🚨 Démarrage et fin d'exécution de l'expérience
    mlflow.start_run()
    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
    lr.fit(train_x, train_y)

    # Prédiction des qualités pour les données de test
    predicted_qualities = lr.predict(test_x)

    # Évaluation des performances du modèle avec les métriques
    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)

    # Affichage des résultats
    print("ElasticNet model (alpha={:f}, l1_ratio={:f}):".format(alpha, l1_ratio))
    print("  RMSE: %s" % rmse)
    print("  MAE: %s" % mae)
    print("  R2: %s" % r2)

    # Enregistrement des paramètres et métriques dans MLflow
    mlflow.log_param("alpha", alpha)
    mlflow.log_param("l1_ratio", l1_ratio)
    mlflow.log_metric("rmse", rmse)
    mlflow.log_metric("r2", r2)
    mlflow.log_metric("mae", mae)

    # 💀🚨 Enregistrement du modèle avec un nouveau nom
    mlflow.sklearn.log_model(lr, "my_new_model_1")

    # 💀🚨 Terminer l'exécution et récupérer la dernière exécution active
    mlflow.end_run()
    run = mlflow.last_active_run()
    print("Active run id is {}".format(run.info.run_id))
    print("Active run name is {}".format(run.info.run_name))
```

---

Avec ce tutoriel complet, chaque ajout par rapport au script précédent est bien mis en évidence pour faciliter le suivi et l’apprentissage des nouvelles fonctionnalités !
